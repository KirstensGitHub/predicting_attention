{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5f09d0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c76cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stimulus_helpers import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ee1cf",
   "metadata": {},
   "source": [
    "### Function to make mistmatched stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7e9cd",
   "metadata": {},
   "source": [
    "In experiment 3, we showed valid attention sequences over the wrong image backgrounds (\"mismatched\" background images). Here we define functions to create mismatched stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2390ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_maker_mismatch(fixations, dictionary, this_list, this_version, stim_type, isolated=False, background=[], background_list=[]):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    \n",
    "    fixations  - pandas dataframe containing only fixation data from one subject viewing one image\n",
    "    dictionary - dictionary containing two keys, one with the image name and one with the fixaiton coordinates \n",
    "    stim_type  - string describing the type of attention stimulus to make: veridical / scrambled / mismatched / reversed\n",
    "    isolated   - boolean describing whether the attention will be isolated (True) or be overlaid on an image (False)\n",
    "            \n",
    "    OUTPUTS: \n",
    "    \n",
    "    technically, none\n",
    "    \n",
    "    This will create and save two files: \n",
    "    - mp4 video of the attention video stimulus\n",
    "    - csv containing video metadata\n",
    "        - # of attention chunks (num_chunks)\n",
    "        - order of attention chunks (order)\n",
    "        - image filename (dictionary['image'])\n",
    "        - subject ID (dictionary['subject'])\n",
    "    '''\n",
    "    \n",
    "    # This function can make veridical and scrambled attention spotlight videos, isolated or overlaid on an image\n",
    "\n",
    "    lengths = []; movie_frames = []; total_counter = 0\n",
    "    order   = list(set(fixations))\n",
    "    num_chunks = len(order)\n",
    "\n",
    "    if len(order)>2:\n",
    "\n",
    "        # scramble order for scrambled stimulus\n",
    "        if stim_type=='scrambled':\n",
    "            while order == list(range(1, len(order)+1)):\n",
    "                remainder = order[1:]\n",
    "                np.random.shuffle(remainder)\n",
    "                new_list = [order[0]] + list(remainder)\n",
    "                order = new_list\n",
    "\n",
    "        # record how many chunks stay in the same place (besides the first one), if any\n",
    "        number_same = sum(x == y for x, y in zip(order, list(range(1, len(order)+1))))-1\n",
    "            \n",
    "        # for each fixation chunk \n",
    "        for x in order:\n",
    "    \n",
    "            length_counter = 0; tuple_list = []; total_list = []\n",
    "\n",
    "            # for first chunk, collect the largest and smallest x and y vals\n",
    "            if x==1:\n",
    "            \tx1_vals=[100000000000,0]; y1_vals=[100000000000,0]\n",
    "            \t# initialize very high and very low values, respectively\n",
    "\n",
    "            # for each item in fixie chunk list AND each tuple\n",
    "            for a,b in zip(fixations, dictionary['fixations']):\n",
    "\n",
    "                # if item from fixie chunk list is the number from first for statement:\n",
    "                if a == x:\n",
    "                    tuple_list.append(b)\n",
    "                    total_counter += 1\n",
    "                    total_list.append(total_counter)\n",
    "                    if x==1:\n",
    "                    \tx1_vals,y1_vals = first_bounds_update(x1_vals,y1_vals,b)\n",
    "            \n",
    "            # determine if first hotspot contains center of screen\n",
    "            first_centered   = one_centered(x1_vals, y1_vals)\n",
    "            reverse_centered = one_centered(y1_vals, x1_vals)\n",
    "\n",
    "            # pass into plotting function\n",
    "            plot_heatmap_mismatch({'image':dictionary['image'], 'fixations':tuple_list}, \n",
    "                         filename='/Users/kirstenziman/Downloads/Images_resized_greyborders/List'+str(this_list)+'/' + dictionary['image'], \n",
    "                         alpha=.6, cmap=\"Greys_r\", clean=False, isolated=isolated, other=True, l=this_list,\n",
    "                                 background=background, background_list=background_list)\n",
    "            # images_with_borders/\n",
    "            \n",
    "            # save jpegs    \n",
    "            for q in total_list:\n",
    "                addin = get_addin(q)\n",
    "                plt.savefig(dictionary['image']+addin+str(q)+'.jpg')\n",
    "\n",
    "        # determine frame rate given number of images\n",
    "        framerate = get_framerate()\n",
    "\n",
    "        if framerate!=0:\n",
    "            ending = '_'+dictionary['subject'][0]+'_L'+str(this_list)+'_V'+str(this_version)+'_'+stim_type+'_freeview_iso'+str(isolated)+'mismatch_'+background+'_L'+str(background_list)\n",
    "\n",
    "        # compile and save video\n",
    "            (\n",
    "            ffmpeg\n",
    "            .input('*.jpg', pattern_type='glob', framerate=framerate)\n",
    "            .output(dictionary['image']+ending+'.mp4')\n",
    "            .run()\n",
    "            )\n",
    "            \n",
    "            # remove leftover jpeg images\n",
    "            remove_jpegs()\n",
    "\n",
    "        else:\n",
    "            print('framerate is zero for '+dictionary['image'])\n",
    "\n",
    "            for file_name in os.listdir('.'):\n",
    "                if file_name.endswith('.jpg'):\n",
    "                    os.remove(file_name)\n",
    "\n",
    "        meta = pd.DataFrame({'image':dictionary['image'],'subject':dictionary['subject'],'num_chunks':num_chunks, 'order':[order], 'center_first':str(first_centered), 'center_first_reverse':str(reverse_centered), 'chunks_same': number_same, 'proportion_same':number_same/(len(order)-1), 'x1_vals':[x1_vals], 'y1_vals':[y1_vals],\n",
    "                            'background_image':background,'background_list':background_list})\n",
    "\n",
    "        meta.to_csv(dictionary['image']+ending+'.csv')\n",
    "\n",
    "    else:\n",
    "        print('len(k) <= 2: '+dictionary['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2504518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KZ added \"isolated attention\" option \n",
    "# def plot_heatmap(data, filename='test.pdf', alpha=0.7, cmap='jet', clean=True):\n",
    "def plot_heatmap_mismatch(data, filename='test.pdf', alpha=0.7, cmap='jet', clean=True, isolated=False, other=None, l=1, background=[], background_list=[]):\n",
    "    \"\"\"\n",
    "    Plot heatmap.\n",
    "    Mostly modified from PyGaze.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    image      = data['image']\n",
    "    image_path = '/Users/kirstenziman/Downloads/Images_resized_greyborders/List '+str(l)+'/'+data['image'] # IMAGE_PATHS[image]\n",
    "    #KZ update from ndimage to imageio #image_data = ndimage.imread(image_path)\n",
    "    # images_with_borders/\n",
    "    image_data = imageio.imread(image_path)\n",
    "    heatmap    = buildFixMap(data['fixations'])\n",
    "    # Remove haze.\n",
    "    if clean:\n",
    "        heatmap = clean_heatmap(heatmap)\n",
    "    \n",
    "    # Matplotlib.\n",
    "    # Borrows heavily from from Edwin Dalmaijer's `gazeplotter.py` script, from the PyGaze codebase.\n",
    "    dpi = 100\n",
    "    display_size = heatmap.shape\n",
    "    figsize = (display_size[1]/dpi, display_size[0]/dpi)\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi, frameon=False)\n",
    "    ax = plt.Axes(fig, [0,0,1,1])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    if isolated == False and other == None:\n",
    "        ax.imshow(image_data)\n",
    "        # KZ moved ax.imshow(image_data) into if statement for \"isolated attention\" option\n",
    "    \n",
    "    elif other != None:\n",
    "        new_image_path = '/Users/kirstenziman/Downloads/Images_resized_greyborders/List '+str(background_list)+'/'+background\n",
    "        new_image_data = imageio.imread(new_image_path)\n",
    "        ax.imshow(new_image_data)\n",
    "        \n",
    "    ax.imshow(heatmap, cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110fbf8",
   "metadata": {},
   "source": [
    "We use the viewer-attention pairs from experiments 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2cfe612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image info from stim_list_1\n",
    "list1 = [x for x in os.listdir('/Users/kirstenziman/Documents/github/predicting_attention_MRI/pilot_experiment/STIM_SET_1_144/') if x[-6:]=='44.mp4' and 'veridical' in x]\n",
    "\n",
    "# get the image info from stim_list_2\n",
    "list2 = [x for x in os.listdir('/Users/kirstenziman/Documents/predicting_attention/experiments/experiment_6/STIM_SET_2_144/') if x[-6:]=='44.mp4' and 'veridical' in x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b160b",
   "metadata": {},
   "source": [
    "### Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f1d83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2_image = [x[:11] for x in list2]\n",
    "\n",
    "for idx,x in enumerate(list2_image):\n",
    "    if x[-1]=='_':\n",
    "        list2_image[idx]=x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e23379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_image = [x[:11] for x in list1]\n",
    "\n",
    "for idx,x in enumerate(list1_image):\n",
    "    if x[-1]=='_':\n",
    "        list1_image[idx]=x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "777e23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,x in enumerate(list1_image):\n",
    "    if x[-2:]=='_p':\n",
    "        list1_image[idx]=x[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c4e6a",
   "metadata": {},
   "source": [
    "### Get subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77b30143",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2_sub = [x[11:17] for x in list2]\n",
    "\n",
    "for idx,x in enumerate(list2_sub):\n",
    "    if x[0]=='_':\n",
    "        list2_sub[idx]=x[1:]\n",
    "        \n",
    "    if list2_sub[idx][-1]=='L':\n",
    "        list2_sub[idx]=list2_sub[idx][:-1]\n",
    "        \n",
    "    if list2_sub[idx][-1]=='_':\n",
    "        list2_sub[idx]=list2_sub[idx][:-1]\n",
    "        \n",
    "#list2_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dc31454",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1_sub = [x[10:17] for x in list1]\n",
    "\n",
    "for idx,x in enumerate(list1_sub):\n",
    "    if x[0]=='_':\n",
    "        list1_sub[idx]=x[1:]\n",
    "        \n",
    "    if x[0:2]=='p_':\n",
    "        list1_sub[idx]=x[2:]\n",
    "        \n",
    "    if list1_sub[idx][-1]=='L':\n",
    "        list1_sub[idx]=list1_sub[idx][:-1]\n",
    "        \n",
    "    if list1_sub[idx][-1]=='_':\n",
    "        list1_sub[idx]=list1_sub[idx][:-1]\n",
    "        \n",
    "    if list1_sub[idx][-3:]=='_L3':\n",
    "        list1_sub[idx]=list1_sub[idx][:-3]\n",
    "        \n",
    "# list1_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e492936",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices  = [x.index('L') for x in list1]\n",
    "\n",
    "listies1 = []\n",
    "\n",
    "for x,y in zip(indices,list1):\n",
    "    listies1.append(int(y[x+1:x+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5cf8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices  = [x.index('L') for x in list2]\n",
    "\n",
    "listies2 = []\n",
    "\n",
    "for x,y in zip(indices,list2):\n",
    "    listies2.append(int(y[x+1:x+2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72194d16",
   "metadata": {},
   "source": [
    "### Make the mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a58e62",
   "metadata": {},
   "source": [
    "Now that we have a list of the subjects, images, and list numbers, we can make the stimulus dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b10703ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81f8739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'image':list1_image, 'subject':list1_sub, \n",
    "                  'list':listies1,'background_image':list2_image[0:70],\n",
    "                 'back_sub':list2_sub[0:70], 'back_list':listies2[0:70]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58a6122f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>background_image</th>\n",
       "      <th>back_sub</th>\n",
       "      <th>back_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498149.bmp</td>\n",
       "      <td>pp99</td>\n",
       "      <td>2</td>\n",
       "      <td>1160189.bmp</td>\n",
       "      <td>pp64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712977.bmp</td>\n",
       "      <td>pp51</td>\n",
       "      <td>1</td>\n",
       "      <td>1159434.bmp</td>\n",
       "      <td>pp62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1592362.bmp</td>\n",
       "      <td>pp95</td>\n",
       "      <td>2</td>\n",
       "      <td>1159575.bmp</td>\n",
       "      <td>pp62</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1592890.bmp</td>\n",
       "      <td>pp82</td>\n",
       "      <td>2</td>\n",
       "      <td>1592305.bmp</td>\n",
       "      <td>pp65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>713135.bmp</td>\n",
       "      <td>pp54</td>\n",
       "      <td>2</td>\n",
       "      <td>285932.bmp</td>\n",
       "      <td>pp64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1592804.bmp</td>\n",
       "      <td>pp91</td>\n",
       "      <td>3</td>\n",
       "      <td>713920.bmp</td>\n",
       "      <td>pp76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>286001.bmp</td>\n",
       "      <td>pp54</td>\n",
       "      <td>2</td>\n",
       "      <td>1592921.bmp</td>\n",
       "      <td>pp69</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1591961.bmp</td>\n",
       "      <td>pp67</td>\n",
       "      <td>2</td>\n",
       "      <td>1159956.bmp</td>\n",
       "      <td>pp59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>498155.bmp</td>\n",
       "      <td>pp61</td>\n",
       "      <td>2</td>\n",
       "      <td>1159329.bmp</td>\n",
       "      <td>pp61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>713513.bmp</td>\n",
       "      <td>pp62</td>\n",
       "      <td>2</td>\n",
       "      <td>61513.bmp_p</td>\n",
       "      <td>p75_L1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image subject  list background_image back_sub  back_list\n",
       "0    498149.bmp    pp99     2      1160189.bmp     pp64          1\n",
       "1    712977.bmp    pp51     1      1159434.bmp     pp62          2\n",
       "2   1592362.bmp    pp95     2      1159575.bmp     pp62          2\n",
       "3   1592890.bmp    pp82     2      1592305.bmp     pp65          3\n",
       "4    713135.bmp    pp54     2       285932.bmp     pp64          1\n",
       "..          ...     ...   ...              ...      ...        ...\n",
       "65  1592804.bmp    pp91     3       713920.bmp     pp76          1\n",
       "66   286001.bmp    pp54     2      1592921.bmp     pp69          3\n",
       "67  1591961.bmp    pp67     2      1159956.bmp     pp59          3\n",
       "68   498155.bmp    pp61     2      1159329.bmp     pp61          2\n",
       "69   713513.bmp    pp62     2      61513.bmp_p   p75_L1          1\n",
       "\n",
       "[70 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a78e88ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('stim10.csv') \n",
    "counter = 0\n",
    "\n",
    "# lr   = list(range(0,70))\n",
    "# random.shuffle(lr) \n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    free_view   = get_gaze(row['subject'],int(row['list']),1,row['image'])\n",
    "    free_fixies = get_fixies(free_view) \n",
    "    free_dicts  = make_the_dicts(free_view)\n",
    "\n",
    "    movie_maker_mismatch(free_fixies, free_dicts, row['list'], 1, 'veridical', \n",
    "                         isolated=False, background=row['background_image'], \n",
    "                         background_list=row['back_list'])\n",
    "                                                      \n",
    "    counter +=1; print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "becb4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_gaze(sub, this_list, this_version, image):\n",
    "#     '''\n",
    "#     INPUTS:\n",
    "#     sub          - string indicating subject ID (example: 'pp151')\n",
    "#     this_list    - int indicating which List the image is from (1, 2, or 3)\n",
    "#     this_version - int indicating which Version of this_list the data is from (1 or 2)\n",
    "    \n",
    "#     OUTPUTS:\n",
    "#     gaze_data    - df containing sub's full gaze data for image \n",
    "#     '''\n",
    "\n",
    "#     subdir     = '../Free_viewing/List'+str(this_list)+'_ALL/'+sub+'/eye'\n",
    "#     eye_trials = os.listdir(subdir)\n",
    "#     null       = 0\n",
    "\n",
    "#     for trial in eye_trials:\n",
    "#         if trial!='.DS_Store' and trial[-3:]!='csv':\n",
    "\n",
    "#             dat_string = subdir+'/'+trial\n",
    "#             splitso    = make_splitso(sub, dat_string, this_list, this_version)\n",
    "\n",
    "#             if 'Stimulus' in splitso.columns:\n",
    "#                 if splitso[splitso['Stimulus']==image].shape[0]>0:\n",
    "#                     free_view = splitso[splitso['Stimulus']==image]\n",
    "#                     null+=1\n",
    "                \n",
    "# #             else:\n",
    "# #                 if warning_counter == 0:\n",
    "# #                     print('No stimulus column in the df')\n",
    "# #                     print(sub)\n",
    "# #                     print(this_list)\n",
    "# #                     print(this_version)\n",
    "# #                     #print(splitso.head())\n",
    "\n",
    "#     if null==0:\n",
    "#         print(\"Reportedly, \"+sub+\" has no values in df for this stimulus: \"+image)\n",
    "#         print(sub)\n",
    "#         print(this_list)\n",
    "#         print(this_version)\n",
    "#         free_view = []\n",
    "#         print(splitso.head())\n",
    "        \n",
    "#     return(free_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af96ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
